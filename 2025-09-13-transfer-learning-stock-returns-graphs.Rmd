---
title: "2025-09-13 Transfer Learning using `ahead::ridge2f` on stocks returns"
author: "T. Moudiki"
date: "2025-09-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Contents**

- 0 - packages
- 0 - functions for generating synthetic stock returns
- 1 - pretraining `ahead::ridge2f` on synthetic stock returns
- 2 - out-of-sample benchmarking with GARCH models
- 3 - out-of-sample benchmarking with GARCH models (continued)

# 0 - packages

```{r 0-pkgs, message=FALSE, warning=FALSE}
# Just in case, uncomment to install packages
#install.packages("pak")
#pak::pak(c('forecast', "rugarch", 
#           "fGarch", 'quantmod', 
#           "zoo"))
#options(repos = c(techtonique = "https://r-packages.techtonique.net",
#                  CRAN = "https://cloud.r-project.org"))
#pak::pak(c('ahead', 'bayesianrvfl'))

require('ahead')
require('bayesianrvfl')
require('forecast')
require("rugarch")
require("fGarch")
require('quantmod')
require('zoo')

```

# 0 - functions for generating synthetic stock returns

```{r 0-functions}
library(forecast)

coverage_score <- function(obj, actual){
  if (is.null(obj$lower))
  {
    return(mean((obj$intervals[, 1] <= actual)*(actual <= obj$intervals[, 2]), na.rm=TRUE)*100)
  }
  return(mean((obj$lower <= actual)*(actual <= obj$upper), na.rm=TRUE)*100)
}
#coverage_score <- memoise::memoise(coverage_score)

winkler_score <- function(obj, actual, level = 95) {
  alpha <- 1 - level / 100
  lt <- try(obj$lower, silent = TRUE)
  ut <- try(obj$upper, silent = TRUE)
  actual <- as.numeric(actual)
  if (is.null(lt) || is.null(ut))
  {
    lt <- as.numeric(obj$intervals[, 1])
    ut <- as.numeric(obj$intervals[, 2])
  }
  n_points <- length(actual)
  stopifnot((n_points == length(lt)) && (n_points == length(ut)))
  diff_lt <- lt - actual
  diff_bounds <- ut - lt
  diff_ut <- actual - ut
  score <- diff_bounds
  score <- score + (2 / alpha) * (pmax(diff_lt, 0) + pmax(diff_ut, 0))
  return(mean(score, na.rm=TRUE))
}
#winkler_score <- memoise::memoise(winkler_score)

accuracy <- function(obj, actual, level = 95)
{
  actual <- as.numeric(actual)
  mean_prediction <- as.numeric(obj$mean)
  me <- mean(mean_prediction - actual)
  rmse <- sqrt(mean((mean_prediction - actual)**2, na.rm=TRUE))
  mae <- mean(abs(mean_prediction - actual), na.rm=TRUE)
  mpe <- mean(mean_prediction/actual-1, na.rm=TRUE)
  mape <- mean(abs(mean_prediction/actual-1), na.rm=TRUE)
  m <- frequency(obj$x)   # e.g., 12 for monthly data
  # Compute scaling factor (MAE of in-sample seasonal naive forecasts)
  if (m > 1) {
    scale <- mean(abs(diff(obj$x, lag = m)), na.rm=TRUE)
  } else {
    scale <- mean(abs(diff(obj$x, lag = 1)), na.rm=TRUE)
  }
  # MASE = mean(|test - forecast|) / scale
  mase <- mean(abs(actual - obj$mean), na.rm=TRUE) / max(scale, 1e-6)
  coverage <- as.numeric(coverage_score(obj, actual))
  winkler <- winkler_score(obj, actual, level = level)
  crps <- mean(scoringRules::crps_sample(y, dat))
  res <- c(me, rmse, mae, mpe,
           mape, mase, coverage, winkler, crps)
  names(res) <- c("me", "rmse", "mae", "mpe",
                  "mape", "mase", "coverage", "winkler", "crps")
  return(res)
}
#accuracy <- memoise::memoise(accuracy)


library(data.table)

# Main synthetic returns generator function
generate_synthetic_returns <- function(
    n_days = 252 * 10,
    mu = 0.0002,
    kappa = 0.05,
    theta = 0.0001,
    sigma_v = 0.01,
    rho = -0.7,
    lambda_jump = 0.05,
    jump_size_dist = "normal",
    sigma_jump = 0.02,
    noise_dist = "normal",
    noise_scale = 0.0005,
    noise_df = 5.0,
    regime_params = NULL,
    random_seed = NULL
) {

  if (!is.null(random_seed)) {
    set.seed(random_seed)
  }

  # Default regime switching parameters
  if (is.null(regime_params)) {
    regime_params <- list(
      transition_matrix = matrix(c(0.99, 0.01, 0.03, 0.97), nrow = 2, byrow = TRUE),
      theta_high_multiplier = 3.0,
      kappa_high_multiplier = 2.0
    )
  }

  # Validate transition matrix
  if (!is.null(regime_params$transition_matrix)) {
    row_sums <- rowSums(regime_params$transition_matrix)
    if (!all(abs(row_sums - 1) < 1e-6)) {
      stop("Transition matrix rows must sum to 1.")
    }
  }

  # Initialize arrays
  n <- n_days
  v <- numeric(n)
  r <- numeric(n)
  regime <- integer(n)

  # Initialize starting values
  v[1] <- theta
  regime[1] <- 0

  # Pre-generate all random numbers
  z_vol <- rnorm(n)
  z_return <- rnorm(n)
  jump_indicators <- rpois(n, lambda = lambda_jump)

  # 1. Simulate the Markov chain for regimes
  for (t in 2:n) {
    prev_regime <- regime[t-1] + 1
    probs <- regime_params$transition_matrix[prev_regime, ]
    regime[t] <- sample(0:1, size = 1, prob = probs)
  }

  # 2. Simulate the Heston process with jumps
  for (t in 2:n) {
    current_regime <- regime[t]
    if (current_regime == 1) {
      theta_t <- theta * regime_params$theta_high_multiplier
      kappa_t <- kappa * regime_params$kappa_high_multiplier
    } else {
      theta_t <- theta
      kappa_t <- kappa
    }

    # Robust volatility discretization
    v_prev <- v[t-1]
    eta <- z_vol[t]

    drift <- kappa_t * (theta_t - max(v_prev, 0))
    volvol_term <- sigma_v * sqrt(max(v_prev, 0)) * eta
    v_new <- v_prev + drift + volvol_term
    v[t] <- max(v_new, 0)

    # Return process
    epsilon_t <- rho * eta + sqrt(1 - rho^2) * z_return[t]
    diffusion_component <- sqrt(max(v_prev, 0)) * epsilon_t

    # Jump process (single jump per period)
    J <- 0
    if (jump_indicators[t] > 0) {
      if (jump_size_dist == "normal") {
        J <- rnorm(1, mean = 0, sd = sigma_jump)
      } else if (jump_size_dist == "log_normal") {
        log_J <- rnorm(1, mean = -0.5 * sigma_jump^2, sd = sigma_jump)
        J <- exp(log_J) - 1
      } else if (jump_size_dist == "exponential") {
        sign <- sample(c(-1, 1), 1)
        J <- sign * rexp(1, rate = 1/sigma_jump)
      } else {
        stop("Invalid jump_size_dist.")
      }
    }

    r[t] <- mu + diffusion_component + J
  }

  # 3. Add microstructure noise
  if (noise_dist == "normal") {
    noise <- rnorm(n, mean = 0, sd = noise_scale)
  } else if (noise_dist == "student_t") {
    if (noise_df <= 2) stop("noise_df must be > 2")
    scale_factor <- noise_scale / sqrt(noise_df / (noise_df - 2))
    noise <- rt(n, df = noise_df) * scale_factor
  } else {
    stop("Invalid noise_dist.")
  }
  r <- r + noise

  # 4. Create output data.table
  dt <- data.table(
    date = seq.Date(as.Date("1970-01-01"), by = "day", length.out = n),
    returns = r,
    variance = v,
    volatility = sqrt(v),
    regime = factor(regime, levels = c(0, 1), labels = c("Low Vol", "High Vol"))
  )

  return(dt)
}

# Wrapper function for generating diverse paths
generate_diverse_sv_paths <- function(
    n_paths = 10000,
    horizon = 252 * 5,
    frequency = "daily",
    jump_type = "mixed",
    include_regime_switching = TRUE,
    random_seed = NULL
) {

  if (!is.null(random_seed)) {
    set.seed(random_seed)
  }

  all_paths <- vector("list", n_paths)
  all_params <- vector("list", n_paths)

  for (i in 1:n_paths) {

    params <- list()

    # Sample diverse parameters
    params$mu <- runif(1, -0.0005, 0.0005)
    params$kappa <- runif(1, 0.02, 0.15)
    params$theta <- runif(1, 5e-5, 3e-4)
    params$sigma_v <- runif(1, 0.005, 0.03)
    params$rho <- runif(1, -0.85, -0.4)

    # Jump parameters
    params$lambda_jump <- sample(c(
      runif(1, 0.005, 0.02),
      runif(1, 0.02, 0.08),
      runif(1, 0.08, 0.15)
    ), 1)

    if (jump_type == "mixed") {
      params$jump_size_dist <- sample(
        c("normal", "log_normal", "exponential"),
        1,
        prob = c(0.4, 0.4, 0.2)
      )
    } else {
      params$jump_size_dist <- jump_type
    }

    params$sigma_jump <- runif(1, 0.01, 0.05)
    params$noise_dist <- sample(c("normal", "student_t"), 1, prob = c(0.7, 0.3))
    params$noise_scale <- runif(1, 1e-5, 2e-4)
    params$noise_df <- runif(1, 3, 8)

    # Regime switching parameters with FIXED transition matrices
    if (include_regime_switching) {
      regime_type <- sample(1:3, 1)

      if (regime_type == 1) {
        # Persistent regimes - FIXED: ensure rows sum to 1
        p11 <- runif(1, 0.97, 0.995)
        p12 <- 1 - p11
        p21 <- runif(1, 0.01, 0.05)
        p22 <- 1 - p21
        transition_matrix <- matrix(c(p11, p12, p21, p22), nrow = 2, byrow = TRUE)
      } else if (regime_type == 2) {
        # Mean-reverting regimes - FIXED: ensure rows sum to 1
        p11 <- runif(1, 0.85, 0.92)
        p12 <- 1 - p11
        p21 <- runif(1, 0.08, 0.15)
        p22 <- 1 - p21
        transition_matrix <- matrix(c(p11, p12, p21, p22), nrow = 2, byrow = TRUE)
      } else {
        # Rapid switching regimes - FIXED: ensure rows sum to 1
        p11 <- runif(1, 0.7, 0.8)
        p12 <- 1 - p11
        p21 <- runif(1, 0.2, 0.3)
        p22 <- 1 - p21
        transition_matrix <- matrix(c(p11, p12, p21, p22), nrow = 2, byrow = TRUE)
      }

      params$regime_params <- list(
        transition_matrix = transition_matrix,
        theta_high_multiplier = runif(1, 2.0, 5.0),
        kappa_high_multiplier = runif(1, 1.5, 3.0)
      )
    } else {
      params$regime_params <- NULL
    }

    # Generate the path
    path_data <- generate_synthetic_returns(
      n_days = horizon,
      mu = params$mu,
      kappa = params$kappa,
      theta = params$theta,
      sigma_v = params$sigma_v,
      rho = params$rho,
      lambda_jump = params$lambda_jump,
      jump_size_dist = params$jump_size_dist,
      sigma_jump = params$sigma_jump,
      noise_dist = params$noise_dist,
      noise_scale = params$noise_scale,
      noise_df = params$noise_df,
      regime_params = params$regime_params
    )

    all_paths[[i]] <- path_data$returns
    all_params[[i]] <- params

    if (i %% 1000 == 0) {
      message(sprintf("Generated %d/%d paths", i, n_paths))
    }
  }

  result <- list(
    paths = all_paths,
    parameters = all_params,
    horizon = horizon,
    frequency = frequency,
    n_paths = n_paths,
    generation_date = Sys.time()
  )

  class(result) <- "diverse_sv_paths"

  return(result)
}

# Summary method for the generated dataset
summary.diverse_sv_paths <- function(object, ...) {
  cat("Diverse Stochastic Volatility Paths Dataset\n")
  cat("===========================================\n")
  cat(sprintf("Number of paths: %d\n", object$n_paths))
  cat(sprintf("Horizon per path: %d days\n", object$horizon))
  cat(sprintf("Generation date: %s\n", object$generation_date))
  cat(sprintf("Total observations: %d\n", object$n_paths * object$horizon))

  # Sample statistics
  sample_paths <- sample(1:object$n_paths, min(100, object$n_paths))
  returns <- unlist(lapply(object$paths[sample_paths], function(x) x))

  cat("\nSummary statistics (sample):\n")
  cat(sprintf("Mean return: %.6f\n", mean(returns)))
  cat(sprintf("Return SD: %.6f\n", sd(returns)))
  cat(sprintf("Skewness: %.3f\n", moments::skewness(returns)))
  cat(sprintf("Kurtosis: %.3f\n", moments::kurtosis(returns)))
  cat(sprintf("Min return: %.6f\n", min(returns)))
  cat(sprintf("Max return: %.6f\n", max(returns)))
}
```

```{r eval=FALSE}
set.seed(12345)
synthetic_data <- generate_diverse_sv_paths(n_paths = 1000, horizon = 500)
synthetic_paths <- synthetic_data$paths
```

# 1 - out-of-sample benchmarking with GARCH models (continued)

```{r 1-load-params}
# Install and load required packages
if (!require("rugarch")) install.packages("rugarch")
if (!require("fGarch")) install.packages("fGarch")
if (!require("forecast")) install.packages("forecast")
library(rugarch)
library(fGarch)
library(forecast)

best_params <- readRDS(file="best_params_with_clustering.rds")
print("Bayesian Optimization Parameters:")
print(best_params$best_param)

params <- list()
params$nb_hidden <- floor(best_params$best_param[1])
params$lags <- floor(best_params$best_param[2])
params$lambda_1 <- 10**best_params$best_param[3]
params$lambda_2 <- 10**best_params$best_param[4]
params$centers <- floor(best_params$best_param[6])
print("Transformed Parameters:")
print(params)
```

# 2 - out-of-sample benchmarking with GARCH models (continued)

```{r 2-additional-benchmark, cache=TRUE}
# Install and load necessary packages
library(quantmod)
library(zoo)

cac40_monthly_returns <- read.csv("~/Documents/Papers/to_submit/2025-09-11-generative-economy/cac40_monthly_returns.csv")
# List of ticker symbols for the CAC40 (example)
# You can replace this with the real tickers from Wikipedia or other sources
cac40_tickers <- colnames(cac40_monthly_returns)[-c(1, 2)]

# Fetch the stock data for each ticker and calculate log-returns
log_returns_list <- list()
date_ <- as.Date("2025-09-05")

for (ticker in cac40_tickers) {
  # Get the stock data for the ticker
  stock <- try(getSymbols(ticker, src = "yahoo", from = date_ - 500, to = date_, auto.assign = TRUE), silent = TRUE)
  if (!inherits(stock, "try-error"))
  {
    # Retrieve the Adjusted Close Prices
    stock_prices <- Cl(get(ticker))
    # Calculate log-returns
    log_returns <- diff(log(stock_prices))
    # Linear interpolation for missing data (weekends)
    log_returns_interpolated <- na.approx(log_returns)
    # Store the log-returns in the list
    log_returns_list[[ticker]] <- log_returns_interpolated 
  }
}

# Convert the list of log-returns into a data frame or matrix
log_returns_matrix <- do.call(cbind, log_returns_list)

# Convert the matrix to a ts object (time series)
log_returns_ts <- ts(log_returns_matrix, start = c(2023, 1), frequency = 252)  # Assuming 252 trading days per year

# View the first few rows of the log-returns time series
#head(log_returns_ts)

# Install and load required packages
if (!require("rugarch")) install.packages("rugarch")
if (!require("fGarch")) install.packages("fGarch")
if (!require("forecast")) install.packages("forecast")
library(rugarch)
library(fGarch)
library(forecast)

best_params <- readRDS(file="best_params_with_clustering.rds")
print("Bayesian Optimization Parameters:")
print(best_params$best_param)

params <- list()
params$nb_hidden <- floor(best_params$best_param[1])
params$lags <- floor(best_params$best_param[2])
params$lambda_1 <- 10**best_params$best_param[3]
params$lambda_2 <- 10**best_params$best_param[4]
params$centers <- floor(best_params$best_param[6])
print("Transformed Parameters:")
print(params)

# Split data into train (90%) and test (10%)
n_series <- ncol(log_returns_ts)
returns_stock_data <- log_returns_ts
print(paste("Data dimensions:", dim(returns_stock_data)[1], "x", dim(returns_stock_data)[2]))

splitted_returns_stock_data <- misc::splitts(returns_stock_data, split_prob = 0.8)
n_test <- length(splitted_returns_stock_data$testing)

# Initialize comprehensive results storage
results <- list()

set.seed(123)

pb <- utils::txtProgressBar(min = 0, max = ncol(log_returns_ts), style = 3)

for (i in seq_len(ncol(log_returns_ts))) {
  series_name <- colnames(log_returns_ts)[i]
  train <- splitted_returns_stock_data$training[, i]
  test <- splitted_returns_stock_data$testing[, i]

  # Store forecasts for each method
  forecasts <- list()
  metrics <- list()

  # --- ridge2f (Transfer Learning Approach) ---
  train_mean <- mean(train)
  train_sd <- sd(train)
  scaled_train <- (train - train_mean) / train_sd

  fit_ridge <- try(ahead::ridge2f(
    y = scaled_train,
    h = length(test),
    nb_hidden = params$nb_hidden,
    lags = min(params$lags, length(scaled_train) - 1L),
    lambda_1 = params$lambda_1,
    lambda_2 = params$lambda_2,
    centers = params$centers,
    level = 95,
    B = 250,
    type_pi = "movingblockbootstrap",
    show_progress = FALSE,
  ), silent = TRUE)

  if (!inherits(fit_ridge, "try-error")) {
    rescaled_mean <- fit_ridge$mean * train_sd + train_mean
    rescaled_lower <- fit_ridge$lower * train_sd + train_mean
    rescaled_upper <- fit_ridge$upper * train_sd + train_mean

    forecasts$ridge2 <- rescaled_mean

    # Calculate comprehensive metrics
    metrics$ridge2 <- list(
      winkler = misc::winkler_score(test, rescaled_lower, rescaled_upper, 95),
      coverage = mean((rescaled_lower <= test) & (test <= rescaled_upper)) * 100,
      interval_width = mean(rescaled_upper - rescaled_lower)
    )
  }

  # --- GARCH using rugarch ---
  garch_spec <- ugarchspec(
    variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
    mean.model = list(armaOrder = c(0, 0), include.mean = FALSE),
    distribution.model = "norm"
  )

  garch_fit <- try(ugarchfit(
    spec = garch_spec,
    data = train,
    solver = "hybrid"
  ), silent = TRUE)

  if (!inherits(garch_fit, "try-error")) {
    garch_forecast <- ugarchforecast(garch_fit, n.ahead = length(test))
    garch_mean <- as.numeric(fitted(garch_forecast))
    garch_sigma <- as.numeric(sigma(garch_forecast))

    z_value <- qnorm(0.975)
    garch_lower <- garch_mean - z_value * garch_sigma
    garch_upper <- garch_mean + z_value * garch_sigma

    forecasts$rugarch <- garch_mean

    metrics$rugarch <- list(
      winkler = misc::winkler_score(test, garch_lower, garch_upper, 95),
      coverage = mean((garch_lower <= test) & (test <= garch_upper)) * 100,
      interval_width = mean(garch_upper - garch_lower)
    )
  }

  # --- GARCH using fGarch ---
  fgarch_fit <- try(garchFit(
    formula = ~ garch(1, 1),
    data = train,
    include.mean = FALSE,
    trace = FALSE,
    cond.dist = "norm"
  ), silent = TRUE)

  if (!inherits(fgarch_fit, "try-error")) {
    fgarch_forecast <- predict(fgarch_fit, n.ahead = length(test))
    fgarch_mean <- rep(0, length(test))  # fGarch assumes zero mean
    fgarch_sigma <- fgarch_forecast$standardDeviation

    z_value <- qnorm(0.975)
    fgarch_lower <- -z_value * fgarch_sigma
    fgarch_upper <- z_value * fgarch_sigma

    forecasts$fgarch <- fgarch_mean

    metrics$fgarch <- list(
      winkler = misc::winkler_score(test, fgarch_lower, fgarch_upper, 95),
      coverage = mean((fgarch_lower <= test) & (test <= fgarch_upper)) * 100,
      interval_width = mean(fgarch_upper - fgarch_lower)
    )
  }

  # Store results for this series
  results[[series_name]] <- list(forecasts = forecasts, metrics = metrics)

  utils::setTxtProgressBar(pb, i)
}
close(pb)

# Create comprehensive summary table
summary_table <- data.frame()
for (series_name in names(results)) {
  for (method in names(results[[series_name]]$metrics)) {
    metrics <- results[[series_name]]$metrics[[method]]
    summary_table <- rbind(summary_table, data.frame(
      Series = series_name,
      Method = method,
      Winkler = metrics$winkler,
      Coverage = metrics$coverage,
      Interval_Width = metrics$interval_width
    ))
  }
}

print(summary_table)



# Median performance across all series
avg_performance <- aggregate(. ~ Method, data = summary_table[, -1], median)
print("\n=== MEDIAN PERFORMANCE ACROSS ALL SERIES ===")
print(avg_performance)

# Statistical significance testing
cat("\n=== STATISTICAL COMPARISON ===\n")
methods <- unique(summary_table$Method)
for (metric in c("Winkler", "Coverage")) {
  cat(paste("\n", metric, "comparison:\n"))
  for (i in 1:(length(methods)-1)) {
    for (j in (i+1):length(methods)) {
      m1 <- summary_table[summary_table$Method == methods[i], metric]
      m2 <- summary_table[summary_table$Method == methods[j], metric]
      test_result <- t.test(m1, m2, paired = TRUE)
      cat(sprintf("%s vs %s: p-value = %.4f%s\n",
                  methods[i], methods[j], test_result$p.value,
                  ifelse(test_result$p.value < 0.05, " *", "")))
    }
  }
}
```

```{r}
library(ggplot2)
library(dplyr)
library(tidyr)
library(viridis)
library(patchwork)

# Assuming 'summary_table' is loaded from your analysis

# 1. Enhanced scatter plots with better styling and annotations
create_enhanced_scatter <- function() {
  
  # Winkler Score Comparison
  p1 <- ggplot(summary_table, aes(x = reorder(Series, Winkler), y = Winkler, color = Method, shape = Method)) +
    geom_point(size = 3, alpha = 0.8) +
    scale_color_viridis_d(name = "Method", option = "plasma") +
    scale_shape_manual(values = c(16, 17, 15), name = "Method") +
    labs(
      title = "Winkler Score by Stock Series and Method",
      subtitle = "Lower values indicate better prediction intervals",
      x = "Stock Series (ordered by Winkler score)",
      y = "Winkler Score"
    ) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 90, hjust = 1, size = 8),
      plot.title = element_text(size = 14, face = "bold"),
      plot.subtitle = element_text(size = 11, color = "gray50"),
      legend.position = "bottom",
      panel.grid.minor = element_blank()
    )
  
  # Coverage Comparison
  p2 <- ggplot(summary_table, aes(x = reorder(Series, Coverage), y = Coverage, color = Method, shape = Method)) +
    geom_point(size = 3, alpha = 0.8) +
    geom_hline(yintercept = 95, linetype = "dashed", color = "red", alpha = 0.7) +
    annotate("text", x = 5, y = 96, label = "Target: 95%", color = "red", size = 3.5) +
    scale_color_viridis_d(name = "Method", option = "plasma") +
    scale_shape_manual(values = c(16, 17, 15), name = "Method") +
    labs(
      title = "Coverage Rate by Stock Series and Method",
      subtitle = "Target coverage: 95% (red dashed line)",
      x = "Stock Series (ordered by coverage)",
      y = "Coverage Rate (%)"
    ) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 90, hjust = 1, size = 8),
      plot.title = element_text(size = 14, face = "bold"),
      plot.subtitle = element_text(size = 11, color = "gray50"),
      legend.position = "bottom",
      panel.grid.minor = element_blank()
    )
  
  # Interval Width Comparison
  p3 <- ggplot(summary_table, aes(x = reorder(Series, Interval_Width), y = Interval_Width, color = Method, shape = Method)) +
    geom_point(size = 3, alpha = 0.8) +
    scale_color_viridis_d(name = "Method", option = "plasma") +
    scale_shape_manual(values = c(16, 17, 15), name = "Method") +
    labs(
      title = "Prediction Interval Width by Stock Series and Method",
      subtitle = "Narrower intervals are preferred (when coverage is adequate)",
      x = "Stock Series (ordered by interval width)",
      y = "Interval Width"
    ) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 90, hjust = 1, size = 8),
      plot.title = element_text(size = 14, face = "bold"),
      plot.subtitle = element_text(size = 11, color = "gray50"),
      legend.position = "bottom",
      panel.grid.minor = element_blank()
    )
  
  return(list(winkler = p1, coverage = p2, interval_width = p3))
}

# 2. Boxplot comparisons for overall method performance
create_method_boxplots <- function() {
  p1 <- ggplot(summary_table, aes(x = Method, y = Winkler, fill = Method)) +
    geom_boxplot(alpha = 0.7, outlier.alpha = 0.6) +
    geom_jitter(width = 0.2, alpha = 0.4, size = 1) +
    scale_fill_viridis_d(option = "plasma") +
    labs(
      title = "Distribution of Winkler Scores by Method",
      subtitle = "Lower is better",
      y = "Winkler Score"
    ) +
    theme_minimal() +
    theme(
      legend.position = "none",
      plot.title = element_text(size = 14, face = "bold"),
      plot.subtitle = element_text(size = 11, color = "gray50")
    )
  
  p2 <- ggplot(summary_table, aes(x = Method, y = Coverage, fill = Method)) +
    geom_boxplot(alpha = 0.7, outlier.alpha = 0.6) +
    geom_jitter(width = 0.2, alpha = 0.4, size = 1) +
    geom_hline(yintercept = 95, linetype = "dashed", color = "red", alpha = 0.7) +
    scale_fill_viridis_d(option = "plasma") +
    labs(
      title = "Distribution of Coverage Rates by Method",
      subtitle = "Target: 95% (red line)",
      y = "Coverage Rate (%)"
    ) +
    theme_minimal() +
    theme(
      legend.position = "none",
      plot.title = element_text(size = 14, face = "bold"),
      plot.subtitle = element_text(size = 11, color = "gray50")
    )
  
  p3 <- ggplot(summary_table, aes(x = Method, y = Interval_Width, fill = Method)) +
    geom_boxplot(alpha = 0.7, outlier.alpha = 0.6) +
    geom_jitter(width = 0.2, alpha = 0.4, size = 1) +
    scale_fill_viridis_d(option = "plasma") +
    labs(
      title = "Distribution of Interval Widths by Method",
      subtitle = "Narrower is generally better",
      y = "Interval Width"
    ) +
    theme_minimal() +
    theme(
      legend.position = "none",
      plot.title = element_text(size = 14, face = "bold"),
      plot.subtitle = element_text(size = 11, color = "gray50")
    )
  
  return(list(winkler = p1, coverage = p2, interval_width = p3))
}

# 3. Method comparison heatmap
create_performance_heatmap <- function() {
  # Calculate median performance by method
  median_performance <- summary_table %>%
    group_by(Method) %>%
    summarise(
      Median_Winkler = median(Winkler),
      Median_Coverage = median(Coverage),
      Median_Interval_Width = median(Interval_Width),
      .groups = 'drop'
    ) %>%
    pivot_longer(cols = starts_with("Median_"), names_to = "Metric", values_to = "Value") %>%
    mutate(Metric = gsub("Median_", "", Metric))
  
  ggplot(median_performance, aes(x = Method, y = Metric, fill = Value)) +
    geom_tile(color = "white", linewidth = 0.5) +
    geom_text(aes(label = round(Value, 4)), color = "white", fontface = "bold", size = 4) +
    scale_fill_viridis_c(name = "Value", option = "plasma") +
    labs(
      title = "Median Performance Heatmap by Method",
      subtitle = "Values shown in cells (lower Winkler & Interval_Width are better, Coverage closer to 95% is better)",
      x = "Method",
      y = "Performance Metric"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 14, face = "bold"),
      plot.subtitle = element_text(size = 10, color = "gray50"),
      axis.text.x = element_text(angle = 45, hjust = 1),
      panel.grid = element_blank()
    )
}

# 4. Pairwise method comparison scatter plots
create_pairwise_comparisons <- function() {
  # Reshape data for pairwise comparisons
  comparison_data <- summary_table %>%
    select(Series, Method, Winkler, Coverage) %>%
    pivot_wider(names_from = Method, values_from = c(Winkler, Coverage))
  
  # Winkler: ridge2 vs rugarch
  p1 <- ggplot(comparison_data, aes(x = Winkler_ridge2, y = Winkler_rugarch)) +
    geom_point(alpha = 0.7, size = 3, color = "steelblue") +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
    geom_smooth(method = "lm", se = TRUE, color = "darkgreen", alpha = 0.3) +
    labs(
      title = "Winkler Score: ridge2f vs rugarch",
      subtitle = "Points below red line favor ridge2f",
      x = "ridge2f Winkler Score",
      y = "rugarch Winkler Score"
    ) +
    theme_minimal() +
    theme(plot.title = element_text(face = "bold"))
  
  # Winkler: ridge2 vs fgarch
  p2 <- ggplot(comparison_data, aes(x = Winkler_ridge2, y = Winkler_fgarch)) +
    geom_point(alpha = 0.7, size = 3, color = "coral") +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
    geom_smooth(method = "lm", se = TRUE, color = "darkgreen", alpha = 0.3) +
    labs(
      title = "Winkler Score: ridge2f vs fGarch",
      subtitle = "Points below red line favor ridge2f",
      x = "ridge2f Winkler Score",
      y = "fGarch Winkler Score"
    ) +
    theme_minimal() +
    theme(plot.title = element_text(face = "bold"))
  
  # Coverage comparison
  p3 <- ggplot(comparison_data, aes(x = Coverage_ridge2, y = Coverage_rugarch)) +
    geom_point(alpha = 0.7, size = 3, color = "purple") +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
    geom_hline(yintercept = 95, linetype = "dotted", color = "blue", alpha = 0.7) +
    geom_vline(xintercept = 95, linetype = "dotted", color = "blue", alpha = 0.7) +
    labs(
      title = "Coverage Rate: ridge2f vs rugarch",
      subtitle = "Blue lines show 95% target coverage",
      x = "ridge2f Coverage (%)",
      y = "rugarch Coverage (%)"
    ) +
    theme_minimal() +
    theme(plot.title = element_text(face = "bold"))
  
  return(list(winkler_ridge_rugarch = p1, winkler_ridge_fgarch = p2, coverage_comparison = p3))
}

# 5. Summary statistics table visualization
create_summary_table_viz <- function() {
  # Calculate comprehensive summary statistics
  method_stats <- summary_table %>%
    group_by(Method) %>%
    summarise(
      Median_Winkler = median(Winkler),
      Q25_Winkler = quantile(Winkler, 0.25),
      Q75_Winkler = quantile(Winkler, 0.75),
      Median_Coverage = median(Coverage),
      Coverage_within_2pct = mean(abs(Coverage - 95) <= 2) * 100,
      Median_Width = median(Interval_Width),
      .groups = 'drop'
    )
  
  # Create a styled table plot
  method_stats_long <- method_stats %>%
    pivot_longer(cols = -Method, names_to = "Statistic", values_to = "Value") %>%
    mutate(Value_formatted = round(Value, 3))
  
  ggplot(method_stats_long, aes(x = Method, y = Statistic, fill = Value)) +
    geom_tile(color = "white", linewidth = 1) +
    geom_text(aes(label = Value_formatted), color = "white", fontface = "bold", size = 3.5) +
    scale_fill_viridis_c(option = "plasma", name = "Value") +
    labs(
      title = "Comprehensive Method Performance Summary",
      subtitle = "Key statistics for each forecasting method",
      x = "Method",
      y = "Performance Statistic"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 14, face = "bold"),
      plot.subtitle = element_text(size = 11, color = "gray50"),
      axis.text.x = element_text(angle = 45, hjust = 1),
      panel.grid = element_blank()
    )
}

# Usage examples:
# Generate all plots
scatter_plots <- create_enhanced_scatter()
boxplot_comparisons <- create_method_boxplots()
heatmap_viz <- create_performance_heatmap()
pairwise_plots <- create_pairwise_comparisons()
summary_viz <- create_summary_table_viz()

# Display individual plots
print(scatter_plots$winkler)
print(scatter_plots$coverage)
print(scatter_plots$interval_width)

# Combined layout using patchwork
combined_boxplots <- boxplot_comparisons$winkler + boxplot_comparisons$coverage + boxplot_comparisons$interval_width
print(combined_boxplots)

# Display other visualizations
print(heatmap_viz)
print(pairwise_plots$winkler_ridge_rugarch)
print(pairwise_plots$coverage_comparison)
print(summary_viz)

# Create a comprehensive dashboard layout
scatter_plots$winkler 
scatter_plots$coverage
boxplot_comparisons$winkler
boxplot_comparisons$coverage
heatmap_viz
```

